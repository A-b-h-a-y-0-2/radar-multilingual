{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing results from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ai_de = \"ai_de_pred.csv\"\n",
    "file_human_de = \"human_de_pred.csv\"\n",
    "human_pred_de =[]\n",
    "ai_pred_de =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_human_it = \"human_it_pred.csv\"\n",
    "file_ai_it = \"ai_it_pred.csv\"\n",
    "ai_pred_it = []\n",
    "human_pred_it = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_human_fr = \"human_fr_pred.csv\"\n",
    "file_ai_fr = \"ai_text_fr_pred.csv\"\n",
    "file_human_tr = \"human_fr_tr.csv\"\n",
    "file_ai_fr_tr = \"ai_fr_tr.csv\"\n",
    "ai_pred_fr = []\n",
    "human_pred_fr = []\n",
    "ai_pred_fr_tr = []\n",
    "human_pred_fr_tr = []\n",
    "with open(file_ai_fr, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        ai_pred_fr.append(float(row[0]))\n",
    "with open(file_human_fr, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        human_pred_fr.append(float(row[0]))\n",
    "with open(file_ai_fr_tr, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        ai_pred_fr_tr.append(float(row[0]))\n",
    "with open(file_human_tr, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        human_pred_fr_tr.append(float(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_human_de_tr = \"human_de_tr_pred.csv\"\n",
    "human_pred_de_tr = []\n",
    "with open(file_human_de_tr, 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        human_pred_de_tr.append(float(row[0]))\n",
    "        human_pred_de_tr.append(float(row[1]))\n",
    "        human_pred_de_tr.append(float(row[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_human_it_tr = \"human_it_tr_pred.csv\"\n",
    "human_pred_it_tr = []\n",
    "with open(file_human_it_tr, 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        human_pred_it_tr.append(float(row[0]))\n",
    "        human_pred_it_tr.append(float(row[1]))\n",
    "        human_pred_it_tr.append(float(row[2]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_ai_de, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        ai_pred_de.append(float(row[0]))\n",
    "with open(file_human_de, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        human_pred_de.append(float(row[0]))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_ai_it, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        ai_pred_it.append(float(row[0]))\n",
    "with open(file_human_it, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        human_pred_it.append(float(row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the probablity of accurately identifying a given text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(human_pred, ai_pred):\n",
    "    count_correct_human = 0\n",
    "    count_incorrect_human = 0\n",
    "    count_correct_ai = 0\n",
    "    for i in human_pred:\n",
    "        if i < 0.5:\n",
    "            count_correct_human+=1\n",
    "        else:\n",
    "            count_incorrect_human +=1\n",
    "    for i in ai_pred:\n",
    "        if i > 0.5:\n",
    "            count_correct_ai +=1\n",
    "    print(\"Probablity of predicting \", (count_correct_human/len(human_pred)), \"human text as human\")\n",
    "    print(\"Probablity of predicting \",(count_incorrect_human)/len(human_pred),\" human text as ai.(FPR)\")\n",
    "    print(\"Probablity of predicting \", (count_correct_ai/len(ai_pred)), \" ai text as ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_single(human_pred):\n",
    "    count_correct_human = 0\n",
    "    count_incorrect_human = 0\n",
    "    for i in human_pred:\n",
    "        if i < 0.5:\n",
    "            count_correct_human+=1\n",
    "        else:\n",
    "            count_incorrect_human+=1\n",
    "    print(\"Probablity of predicting \", (count_correct_human/len(human_pred)), \"human text as human (TPR)\")\n",
    "    print(\"Probablity of predicting \", (count_incorrect_human/len(human_pred)), \"human text as AI (FPR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC is defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_curve\n",
    "def get_roc_metrics(human_preds, ai_preds):\n",
    "    # human_preds is the ai-generated probabiities of human-text\n",
    "    # ai_preds is the ai-generated probabiities of ai-text\n",
    "    if not human_preds or not ai_preds:\n",
    "            # Handle empty arrays to avoid the IndexError\n",
    "            return None    # Rest of your code\n",
    "    fpr, tpr, _ = roc_curve([0] * len(human_preds) + [1] * len(ai_preds), human_preds + ai_preds, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return fpr.tolist(), tpr.tolist(), float(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results over German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of predicting  0.9047 human text as human\n",
      "Probablity of predicting  0.0953  human text as ai.(FPR)\n",
      "Probablity of predicting  0.3287671232876712  ai text as ai\n"
     ]
    }
   ],
   "source": [
    "accuracy(human_pred_de,ai_pred_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.0, 0.0001, 0.0001, 0.0002, 0.0002, 0.0003, 0.0003, 0.0005, 0.0005, 0.001, 0.001, 0.0012, 0.0012, 0.0013, 0.0013, 0.0056, 0.0056, 0.0087, 0.0087, 0.0239, 0.0239, 0.0287, 0.0287, 0.0295, 0.0295, 0.0317, 0.0317, 0.0329, 0.0329, 0.0364, 0.0364, 0.0459, 0.0459, 0.0473, 0.0473, 0.0498, 0.0498, 0.0506, 0.0506, 0.0545, 0.0545, 0.0557, 0.0557, 0.0572, 0.0572, 0.0677, 0.0677, 0.0689, 0.0689, 0.0701, 0.0701, 0.071, 0.071, 0.0726, 0.0726, 0.0741, 0.0741, 0.0782, 0.0782, 0.0801, 0.0801, 0.085, 0.085, 0.0851, 0.0851, 0.087, 0.087, 0.0907, 0.0907, 0.0931, 0.0931, 0.0995, 0.0995, 0.1041, 0.1041, 0.1049, 0.1049, 0.1053, 0.1053, 0.1058, 0.1058, 0.1088, 0.1088, 0.1144, 0.1144, 0.1172, 0.1172, 0.1227, 0.1227, 0.1228, 0.1228, 0.1284, 0.1284, 0.1298, 0.1298, 0.1343, 0.1343, 0.135, 0.135, 0.1413, 0.1413, 0.1459, 0.1459, 0.1518, 0.1518, 0.1552, 0.1552, 0.1558, 0.1558, 0.1587, 0.1587, 0.1668, 0.1668, 0.1707, 0.1707, 0.1736, 0.1736, 0.1745, 0.1745, 0.1791, 0.1791, 0.1821, 0.1821, 0.1829, 0.1829, 0.1836, 0.1836, 0.1855, 0.1855, 0.1862, 0.1862, 0.1945, 0.1945, 0.1962, 0.1962, 0.2078, 0.2078, 0.2089, 0.2089, 0.2096, 0.2096, 0.2105, 0.2105, 0.211, 0.211, 0.2264, 0.2264, 0.2607, 0.2607, 0.2749, 0.2749, 0.275, 0.275, 0.2751, 0.2751, 0.2846, 0.2846, 0.3014, 0.3014, 0.3134, 0.3134, 0.3334, 0.3334, 0.3345, 0.3345, 0.35, 0.35, 0.3521, 0.3521, 0.358, 0.358, 0.3617, 0.3617, 0.3626, 0.3626, 0.3715, 0.3715, 0.3749, 0.3749, 0.3777, 0.3777, 0.3818, 0.3818, 0.384, 0.384, 0.4043, 0.4043, 0.4079, 0.4079, 0.4161, 0.4161, 0.4207, 0.4207, 0.4234, 0.4234, 0.4286, 0.4286, 0.4318, 0.4318, 0.4337, 0.4337, 0.44, 0.44, 0.4412, 0.4412, 0.4494, 0.4494, 0.453, 0.453, 0.4575, 0.4575, 0.4601, 0.4601, 0.4627, 0.4627, 0.4696, 0.4696, 0.4747, 0.4747, 0.485, 0.485, 0.4969, 0.4969, 0.4987, 0.4987, 0.4998, 0.4998, 0.5096, 0.5096, 0.5109, 0.5109, 0.5186, 0.5186, 0.5446, 0.5446, 0.5508, 0.5508, 0.5557, 0.5557, 0.5634, 0.5634, 0.5668, 0.5668, 0.5771, 0.5771, 0.6027, 0.6027, 0.6054, 0.6054, 0.6108, 0.6108, 0.6168, 0.617, 0.6191, 0.6191, 0.6351, 0.6351, 0.6381, 0.6381, 0.6421, 0.6421, 0.6817, 0.6819, 0.6896, 0.6896, 0.7302, 0.7304, 0.7479, 0.7479, 0.8321, 0.8321, 1.0], [0.0, 0.0, 0.0273972602739726, 0.0273972602739726, 0.0684931506849315, 0.0684931506849315, 0.07534246575342465, 0.07534246575342465, 0.08904109589041095, 0.08904109589041095, 0.1095890410958904, 0.1095890410958904, 0.13013698630136986, 0.13013698630136986, 0.136986301369863, 0.136986301369863, 0.14383561643835616, 0.14383561643835616, 0.1506849315068493, 0.1506849315068493, 0.15753424657534246, 0.15753424657534246, 0.1643835616438356, 0.1643835616438356, 0.17123287671232876, 0.17123287671232876, 0.1780821917808219, 0.1780821917808219, 0.18493150684931506, 0.18493150684931506, 0.1917808219178082, 0.1917808219178082, 0.19863013698630136, 0.19863013698630136, 0.2054794520547945, 0.2054794520547945, 0.21232876712328766, 0.21232876712328766, 0.2191780821917808, 0.2191780821917808, 0.22602739726027396, 0.22602739726027396, 0.2328767123287671, 0.2328767123287671, 0.23972602739726026, 0.23972602739726026, 0.2465753424657534, 0.2465753424657534, 0.2534246575342466, 0.2534246575342466, 0.2602739726027397, 0.2602739726027397, 0.2671232876712329, 0.2671232876712329, 0.273972602739726, 0.273972602739726, 0.2808219178082192, 0.2808219178082192, 0.2876712328767123, 0.2876712328767123, 0.2945205479452055, 0.2945205479452055, 0.3013698630136986, 0.3013698630136986, 0.3082191780821918, 0.3082191780821918, 0.3150684931506849, 0.3150684931506849, 0.3219178082191781, 0.3219178082191781, 0.3287671232876712, 0.3287671232876712, 0.3424657534246575, 0.3424657534246575, 0.3493150684931507, 0.3493150684931507, 0.3561643835616438, 0.3561643835616438, 0.363013698630137, 0.363013698630137, 0.3698630136986301, 0.3698630136986301, 0.3767123287671233, 0.3767123287671233, 0.3835616438356164, 0.3835616438356164, 0.3904109589041096, 0.3904109589041096, 0.3972602739726027, 0.3972602739726027, 0.4041095890410959, 0.4041095890410959, 0.410958904109589, 0.410958904109589, 0.4178082191780822, 0.4178082191780822, 0.4246575342465753, 0.4246575342465753, 0.4315068493150685, 0.4315068493150685, 0.4383561643835616, 0.4383561643835616, 0.4452054794520548, 0.4452054794520548, 0.4520547945205479, 0.4520547945205479, 0.4589041095890411, 0.4589041095890411, 0.4657534246575342, 0.4657534246575342, 0.4726027397260274, 0.4726027397260274, 0.4794520547945205, 0.4794520547945205, 0.4863013698630137, 0.4863013698630137, 0.4931506849315068, 0.4931506849315068, 0.5, 0.5, 0.5068493150684932, 0.5068493150684932, 0.5136986301369864, 0.5136986301369864, 0.5205479452054794, 0.5205479452054794, 0.5273972602739726, 0.5273972602739726, 0.5342465753424658, 0.5342465753424658, 0.541095890410959, 0.541095890410959, 0.547945205479452, 0.547945205479452, 0.5547945205479452, 0.5547945205479452, 0.5616438356164384, 0.5616438356164384, 0.5684931506849316, 0.5684931506849316, 0.5753424657534246, 0.5753424657534246, 0.5821917808219178, 0.5821917808219178, 0.589041095890411, 0.589041095890411, 0.5958904109589042, 0.5958904109589042, 0.6027397260273972, 0.6027397260273972, 0.6095890410958904, 0.6095890410958904, 0.6164383561643836, 0.6164383561643836, 0.6232876712328768, 0.6232876712328768, 0.6301369863013698, 0.6301369863013698, 0.636986301369863, 0.636986301369863, 0.6438356164383562, 0.6438356164383562, 0.6506849315068494, 0.6506849315068494, 0.6575342465753424, 0.6575342465753424, 0.6643835616438356, 0.6643835616438356, 0.6712328767123288, 0.6712328767123288, 0.678082191780822, 0.678082191780822, 0.684931506849315, 0.684931506849315, 0.6917808219178082, 0.6917808219178082, 0.6986301369863014, 0.6986301369863014, 0.7054794520547946, 0.7054794520547946, 0.7123287671232876, 0.7123287671232876, 0.7191780821917808, 0.7191780821917808, 0.726027397260274, 0.726027397260274, 0.7328767123287672, 0.7328767123287672, 0.7397260273972602, 0.7397260273972602, 0.7465753424657534, 0.7465753424657534, 0.7534246575342466, 0.7534246575342466, 0.7602739726027398, 0.7602739726027398, 0.7671232876712328, 0.7671232876712328, 0.773972602739726, 0.773972602739726, 0.7808219178082192, 0.7808219178082192, 0.7876712328767124, 0.7876712328767124, 0.7945205479452054, 0.7945205479452054, 0.8013698630136986, 0.8013698630136986, 0.8082191780821918, 0.8082191780821918, 0.815068493150685, 0.815068493150685, 0.821917808219178, 0.821917808219178, 0.8287671232876712, 0.8287671232876712, 0.8356164383561644, 0.8356164383561644, 0.8424657534246576, 0.8424657534246576, 0.8493150684931506, 0.8493150684931506, 0.8561643835616438, 0.8561643835616438, 0.863013698630137, 0.863013698630137, 0.8698630136986302, 0.8698630136986302, 0.8767123287671232, 0.8767123287671232, 0.8835616438356164, 0.8835616438356164, 0.8904109589041096, 0.8904109589041096, 0.8972602739726028, 0.8972602739726028, 0.9041095890410958, 0.9041095890410958, 0.910958904109589, 0.910958904109589, 0.9178082191780822, 0.9178082191780822, 0.9246575342465754, 0.9246575342465754, 0.9315068493150684, 0.9315068493150684, 0.9383561643835616, 0.9383561643835616, 0.9452054794520548, 0.9452054794520548, 0.952054794520548, 0.952054794520548, 0.952054794520548, 0.952054794520548, 0.958904109589041, 0.958904109589041, 0.9657534246575342, 0.9657534246575342, 0.9726027397260274, 0.9726027397260274, 0.9794520547945206, 0.9794520547945206, 0.9794520547945206, 0.9794520547945206, 0.9863013698630136, 0.9863013698630136, 0.9863013698630136, 0.9863013698630136, 0.9931506849315068, 0.9931506849315068, 1.0, 1.0], 0.7603650684931507)\n",
      "0.7603650684931507\n"
     ]
    }
   ],
   "source": [
    "result = get_roc_metrics(human_pred_de,ai_pred_de)\n",
    "print(result)\n",
    "print(result[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results over Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.0, 0.0, 0.0007, 0.0007, 0.0009, 0.0009, 0.0028, 0.0028, 0.0035, 0.0035, 0.0049, 0.0049, 0.0054, 0.0054, 0.0065, 0.0065, 0.0069, 0.0069, 0.0102, 0.0102, 0.0162, 0.0162, 0.0175, 0.0179, 0.0181, 0.0187, 0.019, 0.0207, 0.0211, 0.0213, 0.0216, 0.0218, 0.0222, 0.0225, 0.0246, 0.0248, 0.0249, 0.0252, 0.0253, 0.0255, 0.0259, 0.0261, 0.0262, 0.0264, 0.0269, 0.0269, 0.0275, 0.0278, 0.0281, 0.0283, 0.0285, 0.0287, 0.0289, 0.0293, 0.0306, 0.0309, 0.0314, 0.0316, 0.0317, 0.0319, 0.0328, 0.033, 0.0331, 0.0333, 0.0337, 0.0337, 0.0338, 0.0342, 0.0344, 0.0347, 0.0353, 0.0355, 0.0358, 0.0361, 0.0365, 0.0367, 0.038, 0.0382, 0.0383, 0.0385, 0.0386, 0.039, 0.0399, 0.0402, 0.0409, 0.0412, 0.0417, 0.042, 0.0426, 0.0431, 0.044, 0.0442, 0.0445, 0.0447, 0.0449, 0.0451, 0.0461, 0.0463, 0.0464, 0.0469, 0.0473, 0.0477, 0.0478, 0.0481, 0.0483, 0.0485, 0.0487, 0.049, 0.0492, 0.0502, 0.0504, 0.0507, 0.051, 0.0514, 0.0532, 0.0532, 0.0534, 0.0537, 0.0538, 0.0544, 0.0553, 0.0556, 0.0561, 0.0564, 0.057, 0.0573, 0.0585, 0.0587, 0.0596, 0.0596, 0.0602, 0.0602, 0.0603, 0.0605, 0.0643, 0.0645, 0.0647, 0.0649, 0.0653, 0.0653, 0.0667, 0.0667, 0.0669, 0.0671, 0.0796, 0.0796, 0.0797, 0.0797, 0.0889, 0.0889, 0.0902, 0.0902, 0.0936, 0.0936, 0.0969, 0.0969, 0.0988, 0.099, 0.0991, 0.0991, 0.1004, 0.1004, 0.102, 0.102, 0.1025, 0.1025, 0.1082, 0.1082, 0.109, 0.109, 0.1102, 0.1102, 0.1105, 0.1105, 0.1127, 0.1127, 0.1152, 0.1152, 0.1168, 0.1168, 0.1193, 0.1193, 0.1227, 0.1227, 0.1237, 0.1237, 0.1253, 0.1253, 0.1263, 0.1263, 0.1266, 0.1266, 0.1284, 0.1284, 0.1333, 0.1333, 0.1354, 0.1354, 0.1364, 0.1364, 0.1365, 0.1365, 0.139, 0.139, 0.1402, 0.1402, 0.1409, 0.1409, 0.1421, 0.1421, 0.144, 0.144, 0.1457, 0.1457, 0.1499, 0.1499, 0.1517, 0.1517, 0.1531, 0.1531, 0.1544, 0.1544, 0.1559, 0.1559, 0.1566, 0.1566, 0.1586, 0.1586, 0.1587, 0.1587, 0.1595, 0.1595, 0.1604, 0.1604, 0.1611, 0.1611, 0.1617, 0.1617, 0.1626, 0.1626, 0.1633, 0.1633, 0.1651, 0.1651, 0.1671, 0.1671, 0.1687, 0.1687, 0.1697, 0.1697, 0.1713, 0.1713, 0.1754, 0.1754, 0.1799, 0.1799, 0.1809, 0.1809, 0.1825, 0.1825, 0.1845, 0.1845, 0.1849, 0.1849, 0.1858, 0.1858, 0.1876, 0.1876, 0.1893, 0.1893, 0.1902, 0.1902, 0.1905, 0.1905, 0.1906, 0.1906, 0.1921, 0.1921, 0.1922, 0.1922, 0.1927, 0.1927, 0.1939, 0.1939, 0.1947, 0.1947, 0.1948, 0.1948, 0.1949, 0.1949, 0.195, 0.195, 0.1958, 0.1958, 0.1982, 0.1982, 0.1985, 0.1985, 0.2012, 0.2012, 0.2025, 0.2025, 0.2039, 0.2039, 0.2042, 0.2042, 0.2083, 0.2083, 0.2089, 0.2089, 0.2092, 0.2092, 0.2097, 0.2097, 0.2116, 0.2116, 0.2151, 0.2151, 0.2159, 0.2159, 0.2171, 0.2171, 0.2175, 0.2175, 0.2179, 0.2179, 0.2194, 0.2194, 0.2232, 0.2232, 0.2241, 0.2241, 0.2251, 0.2251, 0.2257, 0.2257, 0.2269, 0.2269, 0.23, 0.23, 0.2478, 0.2478, 0.2502, 0.2502, 0.2515, 0.2515, 0.2554, 0.2554, 0.2566, 0.2566, 0.2584, 0.2584, 0.2653, 0.2653, 0.2719, 0.2719, 0.2742, 0.2742, 0.2802, 0.2802, 0.2807, 0.2807, 0.2827, 0.2827, 0.2833, 0.2833, 0.2848, 0.2848, 0.2862, 0.2862, 0.2874, 0.2874, 0.2879, 0.2879, 0.2919, 0.2919, 0.2922, 0.2922, 0.2924, 0.2924, 0.3027, 0.3027, 0.3062, 0.3062, 0.3069, 0.3069, 0.3265, 0.3265, 0.3275, 0.3275, 0.328, 0.328, 0.3337, 0.3337, 0.3352, 0.3352, 0.3509, 0.3509, 0.3521, 0.3521, 0.3564, 0.3564, 0.3591, 0.3591, 0.3646, 0.3646, 0.3682, 0.3682, 0.3696, 0.3696, 0.3726, 0.3726, 0.3808, 0.3808, 0.3988, 0.3988, 0.4099, 0.4099, 0.4104, 0.4104, 0.4113, 0.4113, 0.419, 0.419, 0.4353, 0.4355, 0.4471, 0.4471, 0.4587, 0.4587, 0.4645, 0.4645, 0.4666, 0.4666, 0.4687, 0.4687, 0.4775, 0.4775, 0.4798, 0.4798, 0.4932, 0.4932, 0.5057, 0.5057, 0.5065, 0.5065, 0.5403, 0.5403, 0.5693, 0.5695, 0.6036, 0.6036, 0.6071, 0.6071, 0.6167, 0.6167, 0.6486, 0.6486, 0.6544, 0.6544, 0.6608, 0.6608, 0.7054, 0.7054, 0.7433, 0.7433, 0.7583, 0.7583, 0.7661, 0.7661, 0.7693, 0.7693, 0.81, 0.8102, 0.8451, 0.8453, 0.8561, 0.8561, 0.9508, 0.9508, 0.9576, 0.9576, 1.0], [0.0, 0.005050505050505051, 0.005050505050505051, 0.010101010101010102, 0.010101010101010102, 0.015151515151515152, 0.015151515151515152, 0.020202020202020204, 0.020202020202020204, 0.025252525252525252, 0.025252525252525252, 0.030303030303030304, 0.030303030303030304, 0.03535353535353535, 0.03535353535353535, 0.04040404040404041, 0.04040404040404041, 0.045454545454545456, 0.045454545454545456, 0.050505050505050504, 0.050505050505050504, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06060606060606061, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.06565656565656566, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.0707070707070707, 0.07575757575757576, 0.07575757575757576, 0.08585858585858586, 0.08585858585858586, 0.08585858585858586, 0.08585858585858586, 0.08585858585858586, 0.08585858585858586, 0.08585858585858586, 0.08585858585858586, 0.09090909090909091, 0.09090909090909091, 0.09595959595959595, 0.09595959595959595, 0.09595959595959595, 0.09595959595959595, 0.10101010101010101, 0.10101010101010101, 0.10606060606060606, 0.10606060606060606, 0.1111111111111111, 0.1111111111111111, 0.12121212121212122, 0.12121212121212122, 0.12626262626262627, 0.12626262626262627, 0.13131313131313133, 0.13131313131313133, 0.13131313131313133, 0.13131313131313133, 0.13636363636363635, 0.13636363636363635, 0.1414141414141414, 0.1414141414141414, 0.14646464646464646, 0.14646464646464646, 0.15151515151515152, 0.15151515151515152, 0.16161616161616163, 0.16161616161616163, 0.16666666666666666, 0.16666666666666666, 0.1717171717171717, 0.1717171717171717, 0.21717171717171718, 0.21717171717171718, 0.2222222222222222, 0.2222222222222222, 0.22727272727272727, 0.22727272727272727, 0.23232323232323232, 0.23232323232323232, 0.23737373737373738, 0.23737373737373738, 0.24242424242424243, 0.24242424242424243, 0.2474747474747475, 0.2474747474747475, 0.25252525252525254, 0.25252525252525254, 0.25757575757575757, 0.25757575757575757, 0.26262626262626265, 0.26262626262626265, 0.2676767676767677, 0.2676767676767677, 0.2727272727272727, 0.2727272727272727, 0.2777777777777778, 0.2777777777777778, 0.2828282828282828, 0.2828282828282828, 0.2878787878787879, 0.2878787878787879, 0.29292929292929293, 0.29292929292929293, 0.29797979797979796, 0.29797979797979796, 0.30303030303030304, 0.30303030303030304, 0.31313131313131315, 0.31313131313131315, 0.3181818181818182, 0.3181818181818182, 0.3282828282828283, 0.3282828282828283, 0.3333333333333333, 0.3333333333333333, 0.3383838383838384, 0.3383838383838384, 0.3434343434343434, 0.3434343434343434, 0.3484848484848485, 0.3484848484848485, 0.35353535353535354, 0.35353535353535354, 0.35858585858585856, 0.35858585858585856, 0.36363636363636365, 0.36363636363636365, 0.3686868686868687, 0.3686868686868687, 0.37373737373737376, 0.37373737373737376, 0.3838383838383838, 0.3838383838383838, 0.3888888888888889, 0.3888888888888889, 0.3939393939393939, 0.3939393939393939, 0.398989898989899, 0.398989898989899, 0.40404040404040403, 0.40404040404040403, 0.4090909090909091, 0.4090909090909091, 0.41414141414141414, 0.41414141414141414, 0.41919191919191917, 0.41919191919191917, 0.42424242424242425, 0.42424242424242425, 0.4292929292929293, 0.4292929292929293, 0.43434343434343436, 0.43434343434343436, 0.4393939393939394, 0.4393939393939394, 0.4444444444444444, 0.4444444444444444, 0.4494949494949495, 0.4494949494949495, 0.45454545454545453, 0.45454545454545453, 0.4595959595959596, 0.4595959595959596, 0.46464646464646464, 0.46464646464646464, 0.4696969696969697, 0.4696969696969697, 0.47474747474747475, 0.47474747474747475, 0.48484848484848486, 0.48484848484848486, 0.4898989898989899, 0.4898989898989899, 0.494949494949495, 0.494949494949495, 0.5, 0.5, 0.5050505050505051, 0.5050505050505051, 0.51010101010101, 0.51010101010101, 0.5151515151515151, 0.5151515151515151, 0.5202020202020202, 0.5202020202020202, 0.5252525252525253, 0.5252525252525253, 0.5303030303030303, 0.5303030303030303, 0.5353535353535354, 0.5353535353535354, 0.5404040404040404, 0.5404040404040404, 0.5454545454545454, 0.5454545454545454, 0.5505050505050505, 0.5505050505050505, 0.5555555555555556, 0.5555555555555556, 0.5606060606060606, 0.5606060606060606, 0.5656565656565656, 0.5656565656565656, 0.5707070707070707, 0.5707070707070707, 0.5757575757575758, 0.5757575757575758, 0.5808080808080808, 0.5808080808080808, 0.5858585858585859, 0.5858585858585859, 0.5909090909090909, 0.5909090909090909, 0.5959595959595959, 0.5959595959595959, 0.601010101010101, 0.601010101010101, 0.6060606060606061, 0.6060606060606061, 0.6111111111111112, 0.6111111111111112, 0.6161616161616161, 0.6161616161616161, 0.6212121212121212, 0.6212121212121212, 0.6262626262626263, 0.6262626262626263, 0.6313131313131313, 0.6313131313131313, 0.6363636363636364, 0.6363636363636364, 0.6414141414141414, 0.6414141414141414, 0.6464646464646465, 0.6464646464646465, 0.6515151515151515, 0.6515151515151515, 0.6565656565656566, 0.6565656565656566, 0.6616161616161617, 0.6616161616161617, 0.6666666666666666, 0.6666666666666666, 0.6717171717171717, 0.6717171717171717, 0.6767676767676768, 0.6767676767676768, 0.6818181818181818, 0.6818181818181818, 0.6868686868686869, 0.6868686868686869, 0.6919191919191919, 0.6919191919191919, 0.696969696969697, 0.696969696969697, 0.702020202020202, 0.702020202020202, 0.7070707070707071, 0.7070707070707071, 0.7121212121212122, 0.7121212121212122, 0.7171717171717171, 0.7171717171717171, 0.7222222222222222, 0.7222222222222222, 0.7272727272727273, 0.7272727272727273, 0.7323232323232324, 0.7323232323232324, 0.7373737373737373, 0.7373737373737373, 0.7424242424242424, 0.7424242424242424, 0.7474747474747475, 0.7474747474747475, 0.7525252525252525, 0.7525252525252525, 0.7575757575757576, 0.7575757575757576, 0.7626262626262627, 0.7626262626262627, 0.7676767676767676, 0.7676767676767676, 0.7727272727272727, 0.7727272727272727, 0.7777777777777778, 0.7777777777777778, 0.7828282828282829, 0.7828282828282829, 0.7929292929292929, 0.7929292929292929, 0.797979797979798, 0.797979797979798, 0.803030303030303, 0.803030303030303, 0.8080808080808081, 0.8080808080808081, 0.8131313131313131, 0.8131313131313131, 0.8181818181818182, 0.8181818181818182, 0.8232323232323232, 0.8232323232323232, 0.8282828282828283, 0.8282828282828283, 0.8333333333333334, 0.8333333333333334, 0.8383838383838383, 0.8383838383838383, 0.8434343434343434, 0.8434343434343434, 0.8484848484848485, 0.8484848484848485, 0.8535353535353535, 0.8535353535353535, 0.8585858585858586, 0.8585858585858586, 0.8636363636363636, 0.8636363636363636, 0.8686868686868687, 0.8686868686868687, 0.8737373737373737, 0.8737373737373737, 0.8737373737373737, 0.8737373737373737, 0.8787878787878788, 0.8787878787878788, 0.8838383838383839, 0.8838383838383839, 0.8888888888888888, 0.8888888888888888, 0.8939393939393939, 0.8939393939393939, 0.898989898989899, 0.898989898989899, 0.9040404040404041, 0.9040404040404041, 0.9090909090909091, 0.9090909090909091, 0.9141414141414141, 0.9141414141414141, 0.9191919191919192, 0.9191919191919192, 0.9242424242424242, 0.9242424242424242, 0.9292929292929293, 0.9292929292929293, 0.9292929292929293, 0.9292929292929293, 0.9343434343434344, 0.9343434343434344, 0.9393939393939394, 0.9393939393939394, 0.9444444444444444, 0.9444444444444444, 0.9494949494949495, 0.9494949494949495, 0.9545454545454546, 0.9545454545454546, 0.9595959595959596, 0.9595959595959596, 0.9646464646464646, 0.9646464646464646, 0.9696969696969697, 0.9696969696969697, 0.9747474747474747, 0.9747474747474747, 0.9797979797979798, 0.9797979797979798, 0.9848484848484849, 0.9848484848484849, 0.9848484848484849, 0.9848484848484849, 0.9848484848484849, 0.9848484848484849, 0.98989898989899, 0.98989898989899, 0.9949494949494949, 0.9949494949494949, 1.0, 1.0], 0.7604863636363637)\n",
      "0.7604863636363637\n"
     ]
    }
   ],
   "source": [
    "result = get_roc_metrics(human_pred_it,ai_pred_it)\n",
    "print(result)\n",
    "print(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of predicting  0.7958 human text as human\n",
      "Probablity of predicting  0.2042  human text as ai.(FPR)\n",
      "Probablity of predicting  0.5656565656565656  ai text as ai\n"
     ]
    }
   ],
   "source": [
    "accuracy(human_pred_it, ai_pred_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results over French\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.0, 0.0, 0.0, 0.004975124378109453, 0.004975124378109453, 0.009950248756218905, 0.009950248756218905, 0.014925373134328358, 0.014925373134328358, 0.024875621890547265, 0.024875621890547265, 0.029850746268656716, 0.029850746268656716, 0.03482587064676617, 0.03482587064676617, 0.03980099502487562, 0.03980099502487562, 0.04477611940298507, 0.04477611940298507, 0.04975124378109453, 0.04975124378109453, 0.05472636815920398, 0.05472636815920398, 0.06467661691542288, 0.06467661691542288, 0.07960199004975124, 0.07960199004975124, 0.0845771144278607, 0.0845771144278607, 0.08955223880597014, 0.08955223880597014, 0.0945273631840796, 0.0945273631840796, 0.09950248756218906, 0.09950248756218906, 0.10945273631840796, 0.10945273631840796, 0.11442786069651742, 0.11442786069651742, 0.11940298507462686, 0.11940298507462686, 0.12437810945273632, 0.12437810945273632, 0.13930348258706468, 0.13930348258706468, 0.17412935323383086, 0.17412935323383086, 0.1890547263681592, 0.1890547263681592, 0.19900497512437812, 0.19900497512437812, 0.21393034825870647, 0.21393034825870647, 0.22388059701492538, 0.22388059701492538, 0.24378109452736318, 0.24378109452736318, 0.24875621890547264, 0.24875621890547264, 0.25870646766169153, 0.25870646766169153, 0.263681592039801, 0.263681592039801, 0.26865671641791045, 0.26865671641791045, 0.2736318407960199, 0.2736318407960199, 0.2835820895522388, 0.2835820895522388, 0.2885572139303483, 0.2885572139303483, 0.29850746268656714, 0.29850746268656714, 0.30845771144278605, 0.30845771144278605, 0.32338308457711445, 0.32338308457711445, 0.34328358208955223, 0.34328358208955223, 0.373134328358209, 0.373134328358209, 0.38308457711442784, 0.38308457711442784, 0.39303482587064675, 0.39303482587064675, 0.40298507462686567, 0.40298507462686567, 0.4079601990049751, 0.4079601990049751, 0.4228855721393035, 0.4228855721393035, 0.44776119402985076, 0.44776119402985076, 0.4577114427860697, 0.4577114427860697, 0.46766169154228854, 0.46766169154228854, 0.48258706467661694, 0.48258706467661694, 0.5174129353233831, 0.5174129353233831, 0.5373134328358209, 0.5373134328358209, 0.582089552238806, 0.582089552238806, 0.5870646766169154, 0.5870646766169154, 0.6069651741293532, 0.6069651741293532, 0.6218905472636815, 0.6218905472636815, 0.6318407960199005, 0.6318407960199005, 0.6417910447761194, 0.6417910447761194, 0.6716417910447762, 0.6716417910447762, 0.6865671641791045, 0.6865671641791045, 0.7164179104477612, 0.7164179104477612, 0.7213930348258707, 0.7213930348258707, 0.7313432835820896, 0.7313432835820896, 0.736318407960199, 0.736318407960199, 0.7562189054726368, 0.7562189054726368, 0.7611940298507462, 0.7611940298507462, 0.7810945273631841, 0.7810945273631841, 0.7960199004975125, 0.7960199004975125, 0.8059701492537313, 0.8059701492537313, 0.8109452736318408, 0.8109452736318408, 0.8159203980099502, 0.8159203980099502, 0.8208955223880597, 0.8208955223880597, 0.8258706467661692, 0.8258706467661692, 0.845771144278607, 0.845771144278607, 0.8656716417910447, 0.8656716417910447, 0.8756218905472637, 0.8756218905472637, 0.8805970149253731, 0.8805970149253731, 0.8955223880597015, 0.8955223880597015, 0.900497512437811, 0.900497512437811, 0.9104477611940298, 0.9104477611940298, 0.9253731343283582, 0.9253731343283582, 0.9402985074626866, 0.9402985074626866, 0.945273631840796, 0.945273631840796, 0.9502487562189055, 0.9502487562189055, 0.9601990049751243, 0.9601990049751243, 0.9751243781094527, 0.9751243781094527, 0.9850746268656716, 0.9850746268656716, 0.9950248756218906, 0.9950248756218906, 1.0], [0.0, 0.004975124378109453, 0.06965174129353234, 0.06965174129353234, 0.09950248756218906, 0.09950248756218906, 0.11940298507462686, 0.11940298507462686, 0.2885572139303483, 0.2885572139303483, 0.3034825870646766, 0.3034825870646766, 0.31840796019900497, 0.31840796019900497, 0.35323383084577115, 0.35323383084577115, 0.36318407960199006, 0.36318407960199006, 0.39303482587064675, 0.39303482587064675, 0.4129353233830846, 0.4129353233830846, 0.417910447761194, 0.417910447761194, 0.43781094527363185, 0.43781094527363185, 0.4427860696517413, 0.4427860696517413, 0.46766169154228854, 0.46766169154228854, 0.47761194029850745, 0.47761194029850745, 0.48258706467661694, 0.48258706467661694, 0.4925373134328358, 0.4925373134328358, 0.4975124378109453, 0.4975124378109453, 0.5024875621890548, 0.5024875621890548, 0.5124378109452736, 0.5124378109452736, 0.5174129353233831, 0.5174129353233831, 0.5323383084577115, 0.5323383084577115, 0.5422885572139303, 0.5422885572139303, 0.5472636815920398, 0.5472636815920398, 0.5522388059701493, 0.5522388059701493, 0.5621890547263682, 0.5621890547263682, 0.5671641791044776, 0.5671641791044776, 0.572139303482587, 0.572139303482587, 0.5771144278606966, 0.5771144278606966, 0.5870646766169154, 0.5870646766169154, 0.5920398009950248, 0.5920398009950248, 0.5970149253731343, 0.5970149253731343, 0.6019900497512438, 0.6019900497512438, 0.6069651741293532, 0.6069651741293532, 0.6119402985074627, 0.6119402985074627, 0.6169154228855721, 0.6169154228855721, 0.6218905472636815, 0.6218905472636815, 0.6268656716417911, 0.6268656716417911, 0.6318407960199005, 0.6318407960199005, 0.6368159203980099, 0.6368159203980099, 0.6467661691542289, 0.6467661691542289, 0.6616915422885572, 0.6616915422885572, 0.6666666666666666, 0.6666666666666666, 0.6716417910447762, 0.6716417910447762, 0.6766169154228856, 0.6766169154228856, 0.681592039800995, 0.681592039800995, 0.6865671641791045, 0.6865671641791045, 0.6915422885572139, 0.6915422885572139, 0.6965174129353234, 0.6965174129353234, 0.7014925373134329, 0.7014925373134329, 0.7064676616915423, 0.7064676616915423, 0.7213930348258707, 0.7213930348258707, 0.736318407960199, 0.736318407960199, 0.746268656716418, 0.746268656716418, 0.7512437810945274, 0.7512437810945274, 0.7562189054726368, 0.7562189054726368, 0.7611940298507462, 0.7611940298507462, 0.7661691542288557, 0.7661691542288557, 0.7761194029850746, 0.7761194029850746, 0.7810945273631841, 0.7810945273631841, 0.7860696517412935, 0.7860696517412935, 0.7910447761194029, 0.7910447761194029, 0.7960199004975125, 0.7960199004975125, 0.8009950248756219, 0.8009950248756219, 0.8059701492537313, 0.8059701492537313, 0.8109452736318408, 0.8109452736318408, 0.8159203980099502, 0.8159203980099502, 0.8208955223880597, 0.8208955223880597, 0.8258706467661692, 0.8258706467661692, 0.8308457711442786, 0.8308457711442786, 0.8407960199004975, 0.8407960199004975, 0.845771144278607, 0.845771144278607, 0.8606965174129353, 0.8606965174129353, 0.8706467661691543, 0.8706467661691543, 0.8756218905472637, 0.8756218905472637, 0.8805970149253731, 0.8805970149253731, 0.8855721393034826, 0.8855721393034826, 0.8905472636815921, 0.8905472636815921, 0.8955223880597015, 0.8955223880597015, 0.900497512437811, 0.900497512437811, 0.9054726368159204, 0.9054726368159204, 0.9104477611940298, 0.9104477611940298, 0.9203980099502488, 0.9203980099502488, 0.9402985074626866, 0.9402985074626866, 0.9502487562189055, 0.9502487562189055, 0.9651741293532339, 0.9651741293532339, 1.0, 1.0], 0.6813197693126408)\n",
      "0.6813197693126408\n"
     ]
    }
   ],
   "source": [
    "human_pred_fr = human_pred_fr[:len(ai_pred_fr)] # to remove bias\n",
    "result = get_roc_metrics(human_pred_fr,ai_pred_fr)\n",
    "print(result)\n",
    "print(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of predicting  0.8557213930348259 human text as human\n",
      "Probablity of predicting  0.14427860696517414  human text as ai.(FPR)\n",
      "Probablity of predicting  0.5323383084577115  ai text as ai\n"
     ]
    }
   ],
   "source": [
    "accuracy(human_pred_fr, ai_pred_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results over German after Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of predicting  0.6631578947368421 human text as human (TPR)\n",
      "Probablity of predicting  0.3368421052631579 human text as AI (FPR)\n"
     ]
    }
   ],
   "source": [
    "accuracy_single(human_pred_de_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results over Italian after Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of predicting  0.4358974358974359 human text as human (TPR)\n",
      "Probablity of predicting  0.5641025641025641 human text as AI (FPR)\n"
     ]
    }
   ],
   "source": [
    "accuracy_single(human_pred_it_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results over French after translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_pred_fr_tr = human_pred_fr_tr[0:201] #to remove bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.0, 0.0, 0.0, 0.004975124378109453, 0.004975124378109453, 0.009950248756218905, 0.009950248756218905, 0.014925373134328358, 0.014925373134328358, 0.01990049751243781, 0.01990049751243781, 0.024875621890547265, 0.024875621890547265, 0.029850746268656716, 0.029850746268656716, 0.03482587064676617, 0.03482587064676617, 0.03980099502487562, 0.03980099502487562, 0.04477611940298507, 0.04477611940298507, 0.04975124378109453, 0.04975124378109453, 0.05472636815920398, 0.05472636815920398, 0.05970149253731343, 0.05970149253731343, 0.06965174129353234, 0.06965174129353234, 0.07462686567164178, 0.07462686567164178, 0.07960199004975124, 0.07960199004975124, 0.08955223880597014, 0.08955223880597014, 0.09950248756218906, 0.09950248756218906, 0.1044776119402985, 0.1044776119402985, 0.10945273631840796, 0.10945273631840796, 0.11442786069651742, 0.11442786069651742, 0.11940298507462686, 0.11940298507462686, 0.12437810945273632, 0.12437810945273632, 0.12935323383084577, 0.12935323383084577, 0.13930348258706468, 0.13930348258706468, 0.16417910447761194, 0.16417910447761194, 0.1691542288557214, 0.1691542288557214, 0.17412935323383086, 0.17412935323383086, 0.1791044776119403, 0.1791044776119403, 0.18407960199004975, 0.18407960199004975, 0.1890547263681592, 0.1890547263681592, 0.19402985074626866, 0.19402985074626866, 0.19900497512437812, 0.19900497512437812, 0.21890547263681592, 0.21890547263681592, 0.22388059701492538, 0.22388059701492538, 0.22885572139303484, 0.22885572139303484, 0.23880597014925373, 0.23880597014925373, 0.24875621890547264, 0.24875621890547264, 0.25870646766169153, 0.25870646766169153, 0.2736318407960199, 0.2736318407960199, 0.27860696517412936, 0.27860696517412936, 0.2835820895522388, 0.2835820895522388, 0.3034825870646766, 0.3034825870646766, 0.3283582089552239, 0.3283582089552239, 0.34328358208955223, 0.34328358208955223, 0.3482587064676617, 0.3482587064676617, 0.35323383084577115, 0.35323383084577115, 0.36318407960199006, 0.36318407960199006, 0.38308457711442784, 0.38308457711442784, 0.39800995024875624, 0.39800995024875624, 0.4228855721393035, 0.4228855721393035, 0.42786069651741293, 0.42786069651741293, 0.44776119402985076, 0.44776119402985076, 0.4577114427860697, 0.4577114427860697, 0.4975124378109453, 0.4975124378109453, 0.5024875621890548, 0.5024875621890548, 0.5074626865671642, 0.5074626865671642, 0.5223880597014925, 0.5223880597014925, 0.5373134328358209, 0.5373134328358209, 0.5621890547263682, 0.5621890547263682, 0.6019900497512438, 0.6019900497512438, 0.6268656716417911, 0.6268656716417911, 0.6965174129353234, 0.6965174129353234, 0.7064676616915423, 0.7064676616915423, 0.7860696517412935, 0.7860696517412935, 0.8109452736318408, 0.8109452736318408, 0.945273631840796, 0.945273631840796, 1.0], [0.0, 0.004975124378109453, 0.03482587064676617, 0.03482587064676617, 0.04477611940298507, 0.04477611940298507, 0.05472636815920398, 0.05472636815920398, 0.20398009950248755, 0.20398009950248755, 0.208955223880597, 0.208955223880597, 0.22388059701492538, 0.22388059701492538, 0.2736318407960199, 0.2736318407960199, 0.2885572139303483, 0.2885572139303483, 0.30845771144278605, 0.30845771144278605, 0.32338308457711445, 0.32338308457711445, 0.3333333333333333, 0.3333333333333333, 0.373134328358209, 0.373134328358209, 0.39303482587064675, 0.39303482587064675, 0.39800995024875624, 0.39800995024875624, 0.4129353233830846, 0.4129353233830846, 0.42786069651741293, 0.42786069651741293, 0.48756218905472637, 0.48756218905472637, 0.5024875621890548, 0.5024875621890548, 0.5323383084577115, 0.5323383084577115, 0.5422885572139303, 0.5422885572139303, 0.5572139303482587, 0.5572139303482587, 0.5621890547263682, 0.5621890547263682, 0.5771144278606966, 0.5771144278606966, 0.6119402985074627, 0.6119402985074627, 0.6218905472636815, 0.6218905472636815, 0.6268656716417911, 0.6268656716417911, 0.6368159203980099, 0.6368159203980099, 0.6517412935323383, 0.6517412935323383, 0.6567164179104478, 0.6567164179104478, 0.6616915422885572, 0.6616915422885572, 0.7164179104477612, 0.7164179104477612, 0.746268656716418, 0.746268656716418, 0.7562189054726368, 0.7562189054726368, 0.7661691542288557, 0.7661691542288557, 0.7860696517412935, 0.7860696517412935, 0.7910447761194029, 0.7910447761194029, 0.7960199004975125, 0.7960199004975125, 0.8009950248756219, 0.8009950248756219, 0.8059701492537313, 0.8059701492537313, 0.8159203980099502, 0.8159203980099502, 0.8258706467661692, 0.8258706467661692, 0.835820895522388, 0.835820895522388, 0.8407960199004975, 0.8407960199004975, 0.845771144278607, 0.845771144278607, 0.8557213930348259, 0.8557213930348259, 0.8706467661691543, 0.8706467661691543, 0.8756218905472637, 0.8756218905472637, 0.8805970149253731, 0.8805970149253731, 0.8855721393034826, 0.8855721393034826, 0.8955223880597015, 0.8955223880597015, 0.9054726368159204, 0.9054726368159204, 0.9104477611940298, 0.9104477611940298, 0.9154228855721394, 0.9154228855721394, 0.9253731343283582, 0.9253731343283582, 0.9303482587064676, 0.9303482587064676, 0.9353233830845771, 0.9353233830845771, 0.9402985074626866, 0.9402985074626866, 0.9502487562189055, 0.9502487562189055, 0.9552238805970149, 0.9552238805970149, 0.9601990049751243, 0.9601990049751243, 0.9651741293532339, 0.9651741293532339, 0.9701492537313433, 0.9701492537313433, 0.9751243781094527, 0.9751243781094527, 0.9850746268656716, 0.9850746268656716, 0.9900497512437811, 0.9900497512437811, 0.9950248756218906, 0.9950248756218906, 1.0, 1.0], 0.839533674909037)\n",
      "0.839533674909037\n"
     ]
    }
   ],
   "source": [
    "result = get_roc_metrics(human_pred_fr_tr,ai_pred_fr_tr)\n",
    "print(result)\n",
    "print(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of predicting  0.3582089552238806 human text as human\n",
      "Probablity of predicting  0.6417910447761194  human text as ai.(FPR)\n",
      "Probablity of predicting  0.9701492537313433  ai text as ai\n"
     ]
    }
   ],
   "source": [
    "accuracy(human_pred_fr_tr,ai_pred_fr_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = \"bert-base-multilingual-cased\"\n",
    "base_model = \"bert-base-multilingual-cased\"\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(text, log=False):\n",
    "    with torch.no_grad():\n",
    "        tokenized = base_tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "        logits = base_model(**tokenized).logits[:,:-1]\n",
    "        labels = tokenized.input_ids[:,1:]\n",
    "\n",
    "        # get rank of each label token in the model's likelihood ordering\n",
    "        matches = (logits.argsort(-1, descending=True) == labels.unsqueeze(-1)).nonzero()\n",
    "\n",
    "        assert matches.shape[1] == 3, f\"Expected 3 dimensions in matches tensor, got {matches.shape}\"\n",
    "\n",
    "        ranks, timesteps = matches[:,-1], matches[:,-2]\n",
    "\n",
    "        # make sure we got exactly one match for each timestep in the sequence\n",
    "        assert (timesteps == torch.arange(len(timesteps)).to(timesteps.device)).all(), \"Expected one match per timestep\"\n",
    "\n",
    "        ranks = ranks.float() + 1 # convert to 1-indexed rank\n",
    "        if log:\n",
    "            ranks = torch.log(ranks)\n",
    "\n",
    "        return ranks.float().mean().item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
